{"cells":[{"cell_type":"markdown","id":"3e2b26be","metadata":{"id":"3e2b26be"},"source":["# Time Series Forecasting Exam\n","\n","In this exam, you will work on a time series forecasting task. The goal is to go through the entire workflow from loading the data to evaluating the model and making predictions. Follow each step carefully. The dataset is stored in you can access it [here](https://www.kaggle.com/datasets/khaledzsa/traffic-dataset), the target is to predict `traffic_volume` column. There is also command to download the dataset below.\n","\n","## Dataset: Traffic Dataset\n","\n","### Dataset Overview:\n","\n","- **Name**: Traffic Dataset\n","- **Description**: This dataset contains hourly data on the traffic volume for westbound I-94, a major interstate highway in the US that connects Minneapolis and St Paul, Minnesota. The data was collected by the Minnesota Department of Transportation (MnDOT) from 2012 to 2018 at a station roughly midway between the two cities.\n","- **Time Period**: Starting from 18-11-2016\n","- **Frequency**: Hourly observations\n","\n","### Features:\n","\n","1. **temp:** a numeric variable that shows the average temperature in kelvin.\n","2. **rain_1h:** a numeric variable that shows the amount of rain in mm that occurred in the hour.\n","3. **snow_1h:** a numeric variable that shows the amount of snow in mm that occurred in the hour.\n","4. **clouds_all:** a numeric variable that shows the percentage of cloud cover.\n","5. **weather_main:** a categorical variable that gives a short textual description of the current weather (such as Clear, Clouds, Rain, etc.).\n","6. **weather_description:** a categorical variable that gives a longer textual description of the current weather (such as light rain, overcast clouds, etc.).\n","7. **date_time:** a datetime variable that shows the hour of the data collected in local CST time.\n","8. **traffic_volume:** a numeric variable that shows the hourly I-94 reported westbound traffic volume.\n","\n","#### Feel free to add or rearrange steps as you see fit to optimize your workflow. One additional note: the model's performance doesn't need to be 100% accurate. Instead, focus on achieving the best possible results while balancing performance and generalization."]},{"cell_type":"markdown","id":"9d58f5eb","metadata":{"id":"9d58f5eb"},"source":["## Load the Data\n","\n","Load the time series dataset into a pandas DataFrame.\n","\n","**Instructions:**\n","- Use `pandas` to load your dataset.\n","- Display the first few rows to understand its structure.\n","- Make sure the datetime column is correctly parsed."]},{"cell_type":"code","source":["# Here is a helping code that will download and unzip the dataset for you.\n","# Once you download the dataset you may comment the code!\n","!kaggle datasets download -d khaledzsa/traffic-dataset\n","!unzip traffic-dataset.zip"],"metadata":{"id":"tJG6da7n3tYZ"},"id":"tJG6da7n3tYZ","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"aeb78ac1","metadata":{"id":"aeb78ac1"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"c3122466","metadata":{"id":"c3122466"},"source":["## Exploratory Data Analysis (EDA)\n","\n","Perform exploratory data analysis on the dataset.\n","\n","**Instructions:**\n","- Plot the time series data.\n","- Analyze trends, seasonality, and potential outliers.\n","- Plot boxplots or scatter plots to identify any outliers or anomalies in the data.\n","- Seasonal Decomposition: Use `seasonal_decompose` from the `statsmodels` library to break down the time series data into trend, seasonality, and residual components. Analyze each component to gain insights into the long-term movement (trend), regular patterns (seasonality), and remaining fluctuations (residuals).\n","\n","Do more if needed!"]},{"cell_type":"code","execution_count":null,"id":"05f6fffa","metadata":{"id":"05f6fffa"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"5827fb18","metadata":{"id":"5827fb18"},"source":["## Data Preprocessing\n","\n","Clean and preprocess the data.\n","\n","**Instructions:**\n","- Handle any missing values in the dataset.\n","- If necessary, resample the data to ensure consistent time intervals.\n","- Create any additional features needed, such as lags or moving averages.\n","- Make sure that the dates are sorted correctly.\n","\n","Do more if needed!"]},{"cell_type":"code","execution_count":null,"id":"c27410bc","metadata":{"id":"c27410bc"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"10def3f0","metadata":{"id":"10def3f0"},"source":["## Feature Engineering\n","\n","### Instructions:\n","  \n","- **Shift Method**: Use the `shift` method to create a new column `prev_traffic_volume`, which represents the previous day's traffic volume.\n","\n","- **Difference between traffic_volume**: Calculate the difference between the values in `traffic_volume` column to highlight short-term volume.\n","\n","- **Date Features**: Extract meaningful time-based features from the `date_time` column to enhance the model's ability to detect temporal patterns. These features include:\n","  - **Day of the week**: To capture weekly seasonality.\n","  - **Month**: To capture monthly trends.\n","  - **Day of the year**: Useful for modeling yearly seasonality.\n"]},{"cell_type":"code","execution_count":null,"id":"d62cd837","metadata":{"id":"d62cd837"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"3f9fe326","metadata":{"id":"3f9fe326"},"source":["## Train-Test Split\n","\n","Split the dataset into training and testing sets.\n","\n","**Instructions:**\n","- Ensure the split maintains the time order of the data.\n","- Decide on an appropriate ratio for splitting the data."]},{"cell_type":"code","execution_count":null,"id":"38bd86e0","metadata":{"id":"38bd86e0"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"4bd267bb","metadata":{"id":"4bd267bb"},"source":["## Feature Scaling\n","\n","Apply feature scaling to the data if needed.\n","\n","**Instructions:**\n","- Use a scaling method such as MinMaxScaler or StandardScaler.\n","- Ensure scaling is applied correctly to both training and testing data."]},{"cell_type":"code","execution_count":null,"id":"2a8387e5","metadata":{"id":"2a8387e5"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"4f0be6e9","metadata":{"id":"4f0be6e9"},"source":["## Models Selection\n","\n","Choose two models for time series forecasting.\n","\n","**Instructions:**\n","- Select two models such as ARIMA, SARIMA, RNN, LSTM, or GRU.\n","- Train these models and then compare their performance."]},{"cell_type":"code","execution_count":null,"id":"ffceef22","metadata":{"id":"ffceef22"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"0981f787","metadata":{"id":"0981f787"},"source":["### Model 1 Training\n","\n","Train your first model on the training dataset.\n","\n","**Instructions:**\n","- Fit the first model to the training data.\n","- Ensure to monitor the training process."]},{"cell_type":"code","execution_count":null,"id":"8205ed7f","metadata":{"id":"8205ed7f"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"5f5b3fe3","metadata":{"id":"5f5b3fe3"},"source":["### Make 1 Predictions\n","\n","Generate predictions on the test dataset.\n","\n","### Instructions:\n","- Use the trained model to make predictions on the test data.\n","- Store the predictions for further analysis."]},{"cell_type":"code","execution_count":null,"id":"d1d5cca3","metadata":{"id":"d1d5cca3"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"6489cd08","metadata":{"id":"6489cd08"},"source":["### Model 1 Evaluation\n","\n","Evaluate the performance of your first model on the test dataset.\n","\n","**Instructions:**\n","- Calculate evaluation metrics such as MAE, MSE, RMSE, or MAPE.\n","- Plot the predicted vs actual values for the test set.\n","- Plot the loss and the validation loss."]},{"cell_type":"code","execution_count":null,"id":"aad46e07","metadata":{"id":"aad46e07"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"82dd396a","metadata":{"id":"82dd396a"},"source":["### Model 2 Training\n","\n","Train your second model on the training dataset.\n","\n","**Instructions:**\n","- Fit the second model to the training data.\n","- Ensure to monitor the training process."]},{"cell_type":"code","execution_count":null,"id":"b8605884","metadata":{"id":"b8605884"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"3e811d93","metadata":{"id":"3e811d93"},"source":["### Make 2 Predictions\n","\n","Generate predictions on the test dataset.\n","\n","### Instructions:\n","- Use the trained model to make predictions on the test data.\n","- Store the predictions for further analysis."]},{"cell_type":"code","execution_count":null,"id":"d1492fe0","metadata":{"id":"d1492fe0"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"9d7f7af2","metadata":{"id":"9d7f7af2"},"source":["### Model 2 Evaluation\n","\n","Evaluate the performance of your second model on the test dataset.\n","\n","**Instructions:**\n","- Calculate evaluation metrics such as MAE, MSE, RMSE, or MAPE.\n","- Plot the predicted vs actual values for the test set.\n","- Plot the loss and the validation loss."]},{"cell_type":"code","execution_count":null,"id":"7c3b85de","metadata":{"id":"7c3b85de"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"9cb9e77a","metadata":{"id":"9cb9e77a"},"source":["## Project Questions:\n","\n","1. **Data Preprocessing**: Explain why you chose your specific data preprocessing techniques (e.g., normalization, handling missing values). How did these techniques help prepare the data for training the model?\n","2. **Feature Engineering**: Did you perform any feature engineering or transformations? Describe your decisions and how these new features (or transformed features) contributed to the forecasting model.\n","3. **Model Architecture**: Describe the reasoning behind your modelâ€™s architecture (e.g., the type of model, layers, number of neurons, and activation functions). Why did you believe this architecture was appropriate for time series forecasting?\n","4. **Training Process**: Discuss why you chose your batch size, number of epochs, and optimizer. How did these choices affect the training process? Did you experiment with different values, and what were the outcomes?\n","5. **Loss Function and Metrics**: Why did you choose the specific loss function and evaluation metrics (e.g., MAE, RMSE, MAPE)? How do they align with the objective of forecasting?\n","6. **Model Tuning (If Done)**: Describe any tuning you performed (e.g., hyperparameter tuning) and why you felt it was necessary. How did these adjustments improve model performance?\n","7. **Overfitting and Underfitting**: Analyze whether the model encountered any overfitting or underfitting during training. What strategies could you implement to mitigate these issues?\n","8. **Future Improvements**: Suggest potential improvements or further steps you could take to enhance model performance. Consider using different algorithms, feature engineering techniques, or tuning hyperparameters."]},{"cell_type":"markdown","id":"67ba7c70","metadata":{"id":"67ba7c70"},"source":["### Answer Here:"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}